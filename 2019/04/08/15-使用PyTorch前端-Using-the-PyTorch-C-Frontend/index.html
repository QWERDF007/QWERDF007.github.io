<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="[TOC] Using the PyTorch C++ FrontendPyTorch C++ 文档PyTorch 的 C++ 前端是 PyTorch 机器学习框架的纯 C++ 接口。虽然 PyTorch 的主要接口是 Python，但该 Python API 基于一个 C++ 代码库，提供基本的数据结构和功能，如张量和自动微分。C++ 前端暴露纯 C++ API，在该底层 C++ 代码库之上扩展">
<meta name="keywords" content="ML,Python,PyTorch">
<meta property="og:type" content="article">
<meta property="og:title" content="15.使用PyTorch前端 (Using the PyTorch C++ Frontend)">
<meta property="og:url" content="https://QWERDF007.github.io/2019/04/08/15-使用PyTorch前端-Using-the-PyTorch-C-Frontend/index.html">
<meta property="og:site_name" content="QWERDF007 的博客">
<meta property="og:description" content="[TOC] Using the PyTorch C++ FrontendPyTorch C++ 文档PyTorch 的 C++ 前端是 PyTorch 机器学习框架的纯 C++ 接口。虽然 PyTorch 的主要接口是 Python，但该 Python API 基于一个 C++ 代码库，提供基本的数据结构和功能，如张量和自动微分。C++ 前端暴露纯 C++ API，在该底层 C++ 代码库之上扩展">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-04-08T07:39:48.216Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="15.使用PyTorch前端 (Using the PyTorch C++ Frontend)">
<meta name="twitter:description" content="[TOC] Using the PyTorch C++ FrontendPyTorch C++ 文档PyTorch 的 C++ 前端是 PyTorch 机器学习框架的纯 C++ 接口。虽然 PyTorch 的主要接口是 Python，但该 Python API 基于一个 C++ 代码库，提供基本的数据结构和功能，如张量和自动微分。C++ 前端暴露纯 C++ API，在该底层 C++ 代码库之上扩展">






  <link rel="canonical" href="https://QWERDF007.github.io/2019/04/08/15-使用PyTorch前端-Using-the-PyTorch-C-Frontend/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>15.使用PyTorch前端 (Using the PyTorch C++ Frontend) | QWERDF007 的博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <!--GitHub-start-->
    <a href="https://github.com/QWERDF007" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <!--GitHub-end-->
    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">QWERDF007 的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://QWERDF007.github.io/2019/04/08/15-使用PyTorch前端-Using-the-PyTorch-C-Frontend/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="QWERDF007">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QWERDF007 的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">15.使用PyTorch前端 (Using the PyTorch C++ Frontend)

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-04-08 15:26:47 / Modified: 15:39:48" itemprop="dateCreated datePublished" datetime="2019-04-08T15:26:47+08:00">2019-04-08</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/PyTorch/" itemprop="url" rel="index"><span itemprop="name">PyTorch</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/PyTorch/学习笔记/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2019/04/08/15-使用PyTorch前端-Using-the-PyTorch-C-Frontend/" class="leancloud_visitors" data-flag-title="15.使用PyTorch前端 (Using the PyTorch C++ Frontend)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<h1><span id="using-the-pytorch-c-frontend">Using the PyTorch C++ Frontend</span></h1><p><a href="https://pytorch.org/cppdocs/" target="_blank" rel="noopener">PyTorch C++ 文档</a><br>PyTorch 的 C++ 前端是 PyTorch 机器学习框架的纯 C++ 接口。虽然 PyTorch 的主要接口是 Python，但该 Python API 基于一个 C++ 代码库，提供基本的数据结构和功能，如张量和自动微分。C++ 前端暴露纯 C++ API，在该底层 C++ 代码库之上扩展机器学习训练和推理所需的工具。这包括用于神经网络常用的内置组件的集和；扩展该集和的自定义模块 API；流行的优化算法库，如随机梯度下降；带有定义和加载数据集的 API 的并行数据加载器；序列化程序等等。</p>
<p>本次将了解一个用 C++ 前端训练模型的端到端例子。具体地说，将训练一个 DCGAN，一种生成模型，来生成 MNIST 数字的图像。虽然是个简单的例子，但应该足以快速了解 PyTorch  C++ 前端，并足以训练复杂模型。先解释为何要使用 C++ 前端，然后直接定义和训练模型。</p>
<h1><span id="motivation">Motivation</span></h1><p>在开始令人兴奋的 GANs 和 MNIST 数字的旅程之前，先讨论下为何一开始要用 C++ 前端替代 Python。PyTorch 团队创建 C++ 前端以支持 Python 无法使用，或者不是合适的工具的场景。这些场景包括：</p>
<ul>
<li><strong>低延迟系统：</strong>想在高帧率和低延迟需求的纯 C++ 游戏引擎里进行强化学习研究。使用纯 C++ 库比 Python 库更加适合此环境。由于 Python 解释器很慢，可能不易处理。</li>
<li><strong>高度多线程环境：</strong>由于全局解释器锁(GIL)，Python 一次不能运行多个系统线程。多进程是另一个选择，但不具可扩展性，并且有严重的缺点。C++ 没有这样的限制，并且容易创建和使用线程。需要大量并行化的模型，如<a href="https://eng.uber.com/deep-neuroevolution/" target="_blank" rel="noopener">神经进化</a>中使用的模型，可从中受益。</li>
<li><strong>现有的 C++ 代码库：</strong>在现有的 C++ 程序里想集成机器学习。C++ 前端允许保留在 C++ 中，避免在 Python 和 C++ 间来回绑定的困扰，同时保留 PyTorch(Python) 的大部分灵活性和直观性。</li>
</ul>
<p><strong>Tip：</strong>  </p>
<blockquote>
<p>该 C++ 前端提供尽可能接近 Python&gt; 前端的 API。如果熟悉 Python 前端，并想知道如何在 C++ 前端做同样的事情，可以用 Python 方式编写代码，并且通常在 Python 中可用的函数在 C++ 中也可用(记着用冒号替换点即可)。</p>
</blockquote>
<h1><span id="writing-a-basic-application">Writing a Basic Application</span></h1><p>写一个最小的 C++ 应用，来验证安装和构建环境是一致的。首先，先获取一份 LibTorch 的副本，网上有 zip 归档，封装了所有使用 C++ 前端需要的相关头文件，库和 CMake 编译文件。可以在 <a href="https://pytorch.org/" target="_blank" rel="noopener">PyTorch 网站</a>下载 Linux，MacOS 和 Windows 对应版本的。</p>
<p>接下来，编写一个名为 <code>dcgan.cpp</code> 的小型 C++ 文件，包含 <code>torch/torch.h</code>，并简单打印一个3x3的单位矩阵。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	torch::Tensor tensor = torch::eye(<span class="number">3</span>);</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; tensor &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将使用下面这个 <code>CMakeLists.txt</code> 文件来编译这个小应用和之后完整的训练脚本：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.0</span> FATAL_ERROR)</span><br><span class="line"><span class="keyword">project</span>(dcgan)</span><br><span class="line"></span><br><span class="line"><span class="keyword">find_package</span>(Torch REQUIRED)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(dcgan dcgan.cpp)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(dcgan <span class="string">"$&#123;TORCH_LIBRARIES&#125;"</span>)</span><br><span class="line"><span class="keyword">set_property</span>(<span class="keyword">TARGET</span> dcgan PROPERTY CXX_STANDARD <span class="number">11</span>)</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong>  </p>
<blockquote>
<p>虽然 CMake 是 LibTorch 的推荐编译系统，但这不是硬性需求。你也可以用 Visual Studio，QMake，Makefile 或者其他编译环境。</p>
</blockquote>
<p>注意上面的 CMake 文件的第4行：<code>find_package(Torch REQUIRED)</code>。该行指示 CMake 去查找 LibTorch 库的编译配置。为了让 CMake 知道去哪里查找这些文件，必须在调用 cmake 时设置 <code>CMAKE_PREFIX_PATH</code>。在这之前先查看 dcgan 应用的目录结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dcgan/</span><br><span class="line">    CMakeLists.txt</span><br><span class="line">    dcgan.cpp</span><br></pre></td></tr></table></figure>
<p>此外，指明解压后的 LibTorch 路径为 /path/to/libtorch。注意必须是绝对路径。如果设置 <code>CMAKE_PREFIX_PATH</code> 为 <code>../../libtorch</code>，将会以意想不到的方式中断。反而，设置为 <code>$PWD/../../libtorch</code> 得到相应的绝对路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch ..</span><br></pre></td></tr></table></figure>
<h2><span id="windows">Windows</span></h2><p>Windows 平台下就报错了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA support not available with 32-bit windows.  Did you forget to set</span><br><span class="line">Win64 in the generator target?</span><br></pre></td></tr></table></figure>
<p>清除之前 cmake 产生的(删除 build 文件夹里的内容)，加上 <code>-DCMAKE_GENERATOR_PLATFORM=x64</code> 再重新 cmake，又重新报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Unknown cmake build type</span><br></pre></td></tr></table></figure>
<p>再加上 <code>-DCMAKE_BUILD_TYPE=Release</code> 重新 cmake，cmake 成功，得到 Visual Studio Project。打开后生成 ALL_BUILD，就可以得到exe了，不过会报各种找不到 LibTorch 的 dll，把 /path/to/libtorch/lib 添加至环境变量即可。最终的 CMake 命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch -DCMAKE_GENERATOR_PLATFORM=x64 -DCMAKE_BUILD_TYPE=Release ..</span><br></pre></td></tr></table></figure>
<h2><span id="linux">Linux</span></h2><p>还没试，不知道</p>
<p>Linux 平台 cmake 生成 Makefile，所以还要运行命令 <code>make -j</code>，然后如果没报错就能得到可执行文件。</p>
<h1><span id="defining-the-neural-network-models">Defining the Neural Network Models</span></h1><p>配置好环境后，接下来是更加有趣的部分。首先，先讨论一下如何在 C++ 前端中定义模块并与之交互。先从基础的，小规模的模块开始，然后用 C++ 前端提供的内置模块的库来实现完整的 GAN。</p>
<h2><span id="module-api-basics">Module API Basics</span></h2><p>根据 Python 接口，基于 C++ 前端的神经网络由可重用的构件 <em>modules</em> 组成。有一个基础的模块类，其他模块都由其派生出来。在 Python 中，该类是 <code>torch.nn.Module</code>，而在 C++ 中，它是 <code>torch::nn::Module</code>。除了实现模块封装的算法的 <code>forward()</code> 方法外，模块通常还包括三类子对象：参数，缓存和子模块。</p>
<p>参数和缓存以张量的形式存储状态。参数记录梯度，但缓存不记录。参数通常是神经网络的可训练权重。缓存的示例包括批规范化的均值和方差。为了使用特殊的逻辑块和状态块，PyTorch API 允许模块嵌套。嵌套模块被称为子模块。</p>
<p>参数，缓存和子模块必须显示注册。注册后，可以用 <code>parameters()</code> 或 <code>buffers()</code> 等方法来检索整个(嵌套)模块层次结构的所有参数的容器。类似，<code>to(...)</code> 方法，如 <code>to(torch::kCUDA)</code> 将参数和缓存从 CPU 移动至 CUDA。</p>
<h3><span id="defining-a-module-and-registering-parmmeters">Defining a Module and Registering Parmmeters</span></h3><p>先看一下在 Python 接口定义简单模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, N, M)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.W = torch.nn.Parameter(torch.randn(N, M))</span><br><span class="line">        self.b = torch.nn.Parameter(torch.randn(M))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> torch.addmm(self.b, inputs, self.W)</span><br></pre></td></tr></table></figure>
<p>C++ 接口，看起来像这样：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;</span><br><span class="line">    Net(<span class="keyword">int64_t</span> N, <span class="keyword">int64_t</span> M) &#123;</span><br><span class="line">        W = register_parameter(<span class="string">"W"</span>, torch::randn(&#123;N, M&#125;));</span><br><span class="line">        b = register_parameter(<span class="string">"b"</span>, torch::randn(M));</span><br><span class="line">    &#125;</span><br><span class="line">    torch::<span class="function">Tensor <span class="title">forward</span><span class="params">(torch::Tensor inputs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> torch::addmm(b, inputs, W);</span><br><span class="line">    &#125;</span><br><span class="line">    torch::Tensor W, b;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>就像在 Python 中一样，定义一个类 <code>Net</code> (简单起见，用 <code>struct</code> 代替 <code>class</code>)，由基类 <code>Module</code> 派生。构造函数内，用 <code>torch::randn</code> 创建张量，就像在 Python 中用 <code>torch.randn</code> 一样。一个有趣的区别是如何注册参数。在 Python 中，用 <code>torch.nn.Parameter</code> 类封装张量，而在 C++ 中，必须传递张量至 <code>register_parameter</code> 方法。原因是 Python API 能够检测到属性的类型是 <code>torch.nn.Parameter</code> ，并自动注册这些参数。在 C++ 中，映射是非常有限的，因此提供更传统(和不太神奇)的方法。</p>
<h3><span id="registering-submodules-and-traversing-the-module-hierarchy">Registering Submodules and Traversing the Module Hierarchy</span></h3><p>同样，可以注册参数，也可以注册子模块。在 Python 中，当子模块被指定为模块的属性时，会被自动检测并注册。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, N, M)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(N, M)</span><br><span class="line">        self.another_bias = torch.nn.Parameter(torch.randn(M))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.linear(inputs) + self.another_bias</span><br></pre></td></tr></table></figure>
<p>下面用 <code>parameters()</code> 方法递归访问模块层次的所有参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Net(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(list(net.parameters()))</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[Parameter containing:</span><br><span class="line">tensor([<span class="number">0.0808</span>, <span class="number">0.8613</span>, <span class="number">0.2017</span>, <span class="number">0.5206</span>, <span class="number">0.5353</span>], requires_grad=<span class="keyword">True</span>), Parameter containing:</span><br><span class="line">tensor([[<span class="number">-0.3740</span>, <span class="number">-0.0976</span>, <span class="number">-0.4786</span>, <span class="number">-0.4928</span>],</span><br><span class="line">        [<span class="number">-0.1434</span>,  <span class="number">0.4713</span>,  <span class="number">0.1735</span>, <span class="number">-0.3293</span>],</span><br><span class="line">        [<span class="number">-0.3467</span>, <span class="number">-0.3858</span>,  <span class="number">0.1980</span>,  <span class="number">0.1986</span>],</span><br><span class="line">        [<span class="number">-0.1975</span>,  <span class="number">0.4278</span>, <span class="number">-0.1831</span>, <span class="number">-0.2709</span>],</span><br><span class="line">        [ <span class="number">0.3730</span>,  <span class="number">0.4307</span>,  <span class="number">0.3236</span>, <span class="number">-0.0629</span>]], requires_grad=<span class="keyword">True</span>), Parameter containing:</span><br><span class="line">tensor([ <span class="number">0.2038</span>,  <span class="number">0.4638</span>, <span class="number">-0.2023</span>,  <span class="number">0.1230</span>, <span class="number">-0.0516</span>], requires_grad=<span class="keyword">True</span>)]</span><br></pre></td></tr></table></figure>
<p>在 C++ 中注册子模块，使用命名为 <code>register_module()</code> 的方法注册一个如 <code>torch::nn::Linear</code> 的模块：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;</span><br><span class="line">    Net(<span class="keyword">int64_t</span> N, <span class="keyword">int64_t</span> M) </span><br><span class="line">        : linear(register_module(<span class="string">"linear"</span>, torch::nn::Linear(N, M))) &#123;</span><br><span class="line">        another_bias = register_parameter(<span class="string">"b"</span>, torch::randn(M));</span><br><span class="line">    &#125;</span><br><span class="line">    torch::<span class="function">Tensor <span class="title">forward</span><span class="params">(torch::Tensor inputs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> linear(inputs) + another_bias;</span><br><span class="line">    &#125;</span><br><span class="line">    torch::nn::Linear linear;</span><br><span class="line">    torch::Tensor another_bias;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><strong>Tip：</strong></p>
<blockquote>
<p>可以在 <code>torch::nn</code> 命名空间的<a href="https://pytorch.org/cppdocs/api/namespace_torch__nn.html" target="_blank" rel="noopener">文档</a>里找到全部可用的内置模块，例如 <code>torch::nn::Linear</code>，<code>torch::nn::Dropout</code> 和 <code>torch::nn::Conv2d</code>等。</p>
</blockquote>
<p>上面代码的一个微妙之处就是为什么子模块在构造函数的初始化参数列表创建，而参数在构造函数内创建。这样做是由原因的，将在下面的 C++ 前端模型所有权解释。最后的结果是能够像 Python 一样地递归访问模型的参数。调用 <code>parameters()</code> 返回一个能遍历的 <code>std::vector&lt;torch::Tensor&gt;</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">Net <span class="title">net</span><span class="params">(<span class="number">4</span>, <span class="number">5</span>)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; p : net.parameters()) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; p &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> 1.7211</span><br><span class="line"> 0.0580</span><br><span class="line">-1.4228</span><br><span class="line"> 1.1620</span><br><span class="line"> 0.5306</span><br><span class="line">[ Variable[CPUFloatType]&#123;5&#125; ]</span><br><span class="line"> 0.4241  0.1397  0.4510 -0.1262</span><br><span class="line">-0.3045 -0.3899  0.0257 -0.3681</span><br><span class="line"> 0.4296 -0.4617 -0.1393  0.1869</span><br><span class="line"> 0.0690 -0.2073 -0.1947  0.0203</span><br><span class="line"> 0.2828  0.3223 -0.2057  0.3345</span><br><span class="line">[ Variable[CPUFloatType]&#123;5,4&#125; ]</span><br><span class="line">-0.2389</span><br><span class="line">-0.0193</span><br><span class="line">-0.2718</span><br><span class="line">-0.0299</span><br><span class="line">-0.1455</span><br><span class="line">[ Variable[CPUFloatType]&#123;5&#125; ]</span><br></pre></td></tr></table></figure>
<p>就像在 Python 中一样，这里也有三个参数。C++ API 提供一个 <code>named_parameters()</code> 方法，像 Python 一样返回一个 <code>OrderedDict</code>：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Net <span class="title">net</span><span class="params">(<span class="number">4</span>, <span class="number">5</span>)</span></span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;pair : net.named_parameters()) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; pair.key() &lt;&lt; <span class="string">": "</span> &lt;&lt; pair.value() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行后能看到输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">b:  0.5058</span><br><span class="line"> 0.8766</span><br><span class="line">-0.6075</span><br><span class="line">-0.8279</span><br><span class="line">-1.2091</span><br><span class="line">[ Variable[CPUFloatType]&#123;5&#125; ]</span><br><span class="line">linear.weight:  0.0951 -0.0029 -0.0556  0.1066</span><br><span class="line"> 0.0590  0.1647 -0.3095  0.2760</span><br><span class="line">-0.0195 -0.4368 -0.0953  0.2173</span><br><span class="line">-0.4963  0.2048 -0.1144 -0.4267</span><br><span class="line">-0.0993  0.1745 -0.1132 -0.2479</span><br><span class="line">[ Variable[CPUFloatType]&#123;5,4&#125; ]</span><br><span class="line">linear.bias:  0.0552</span><br><span class="line"> 0.2103</span><br><span class="line">-0.2352</span><br><span class="line">-0.1425</span><br><span class="line"> 0.2188</span><br><span class="line">[ Variable[CPUFloatType]&#123;5&#125; ]</span><br></pre></td></tr></table></figure>
<p><strong>Tip：</strong></p>
<blockquote>
<p><code>torch::nn::Module</code> 的<a href="https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_module.html#exhale-class-classtorch-1-1nn-1-1-module" target="_blank" rel="noopener">文档</a>包含了所有在模块层次结构上操作的方法。</p>
</blockquote>
<h3><span id="running-the-network-in-forward-mode">Running the Network in Forward Mode</span></h3><p>在 C++ 中运行网络，只用简单调用自己定义的 <code>forward()</code> 方法：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">Net <span class="title">net</span><span class="params">(<span class="number">4</span>, <span class="number">5</span>)</span></span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; net.forward(torch::ones(&#123;<span class="number">2</span>, <span class="number">4</span>&#125;)) &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-0.1796  0.4643  0.9377 -0.0865  0.9168</span><br><span class="line">-0.1796  0.4643  0.9377 -0.0865  0.9168</span><br><span class="line">[ Variable[CPUFloatType]&#123;2,5&#125; ]</span><br></pre></td></tr></table></figure>
<h3><span id="module-ownership">Module Ownership</span></h3><p>至此，已经了解如何在 C++ 中定义模块，注册参数，注册子模块，通过 <code>parameters()</code> 等方法遍历模块层次结构，并最终运行模块的 <code>forward()</code> 方法。C++ API 中有许多方法，类和主题需要消化(<a href="https://pytorch.org/cppdocs/api/namespace_torch__nn.html" target="_blank" rel="noopener">文档</a>)。稍后，在实现 DCGAN 模型和端到端训练管道时将介绍更多概念。在这之前，先简单介绍下 C++ 前端为 <code>torch::nn::Module</code> 的子类提供的所有权模型。</p>
<p>所有权模型指的是模块的存储和传递的方式，它决定了谁拥有一个特定的模块实例。在 Python 中，对象总是动态分配在堆上，并且具有引用语义。这非常容易操作，且简单易懂。事实上，在 Python 中很大程度可以忘记对象的位置，以及它们如何被引用，而专注于工作。</p>
<p>C++ 作为一个更加底层的语言，在该领域提供了更多的选择。这增加了复杂性，并严重影响了 C++ 前端的设计和人体工学。尤其，对于 C++ 前端中的模块，可以选择值语义或者引用语义。第一种情况最简单，并已经在出现过的例子中说明：传递给函数时，模块对象被分配在堆上，能被复制，移动(用 <code>std::move</code>)或者通过引用或者指针获取：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">a</span><span class="params">(Net net)</span> </span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">b</span><span class="params">(Net &amp;net)</span> </span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">c</span><span class="params">(Net *net)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Net net;</span><br><span class="line">    a(net);</span><br><span class="line">    a(<span class="built_in">std</span>::move(net));</span><br><span class="line">    b(net);</span><br><span class="line">    c(&amp;net);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于第二种情况，引用语义，可以使用 <code>std::shared_ptr</code>。引用语义的优势是，与 Python 中一样，它减少了思考如何传递模块至函数，和如何声明参数(假设都用 <code>shared_ptr</code>)。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">a</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Net&gt; net)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> net = <span class="built_in">std</span>::make_shared&lt;Net&gt;();</span><br><span class="line">    a(net);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用动态语言的研究者更加喜欢使用引用语义，而不是值语义，尽管后者对于 C++ 更加”本土“。还有一点很重要的要注意，为了更加接近 Python API 的人体工学，<code>torch::nn::Module</code> 的设计依赖于共享的所有权。例如，以之前定义的 <code>Net</code> 为例:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;</span><br><span class="line">    Net(<span class="keyword">int64_t</span> N, <span class="keyword">int64_t</span> M) </span><br><span class="line">        : linear(register_module(<span class="string">"linear"</span>, torch::nn::Linear(N, M))) &#123;&#125;</span><br><span class="line">    torch::nn::Linear linear;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>为了使用 <code>linear</code> 子模块，直接把它存储在类中。然而，想要 Module 基类也能够访问这个子模块。因此，它必须存储对该子模块的引用。至此，已经达到共享所有权的需要。<code>torch::nn::Module</code> 类和具体的 <code>Net</code> 都需要引用子模块。因此，基类存储模块为 <code>shared_ptr</code>，而具体类也要存储。</p>
<p>但上面的代码并没有提及 <code>shared_ptr</code>！为什么会这样？因为 <code>std::shared_prt&lt;MyModule&gt;</code> 要输入太多了。为保证研究人员的效率，<code>Libtorch</code> 提出了一个精心制作的方案，在保留引用语义的同时，隐藏对 <code>shared_ptr</code> 的提及，这通常是值语义的优势。要了解这是如何工作的，看一下核心库中 <code>torch::nn::Linear</code> 的简化定义(<a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/nn/modules/linear.h" target="_blank" rel="noopener">完整定义</a>在此)：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">LinearImpl</span> :</span> torch::nn::Module &#123;</span><br><span class="line">    LinearImpl(<span class="keyword">int64_t</span> in, <span class="keyword">int64_t</span> out);</span><br><span class="line">    <span class="function">Tensor <span class="title">forward</span><span class="params">(<span class="keyword">const</span> Tensor&amp; input)</span></span>;</span><br><span class="line">    Tensor weight, bias;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">TORCH_MODULE(Linear);</span><br></pre></td></tr></table></figure>
<p>这个模块不叫做 <code>Linear</code>，而是 <code>LinearImpl</code>。然后，宏 <code>TORCH_MODULE</code> 定义了真正的 <code>Linear</code> 类。这个”生成的“类实际上是 <code>std::shared_ptr&lt;LinearImpl&gt;</code> 的封装，因此可以用 <code>torch::nn::Linear(3, 4)</code> 代替 <code>std::make_shared&lt;LinearImpl&gt;(3, 4)</code>。由宏创建的类叫做模块<strong>容器</strong>。如(共享)指针类似，可以用箭头操作符访问底层对象(如 <code>model-&gt;forward(...)</code>)。最终结果是一个与 Python API 十分相近的所有权模型。引用语义是默认的，但不需要额外输入 <code>std::shared_ptr</code> 或者 <code>std::make_shared</code>。对于 <code>Net</code> ,使用模块容器 API：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NetImpl</span> :</span> torch::nn::Module &#123;&#125;;</span><br><span class="line">TORCH_MODULE(Net);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">a</span><span class="params">(Net net)</span> </span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Net net;</span><br><span class="line">    a(net);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>默认构造的 <code>std::shared_ptr</code> 为空，即包含空指针。默认构造的 <code>Linear</code> 或者 <code>Net</code> 是什么呢？可以说应该是一个空的 <code>std::shared_ptr&lt;LinearImpl&gt;</code>。但是，请记住，<code>Linear(3, 4)</code> 和 <code>std::shared_ptr&lt;LinearImpl&gt;</code> 是一样的。这意味着如果定义 <code>Linear linear;</code> 应该是空指针，就没办法构造一个不接受然和构造参数的模块。因此，在当前的 API，一个默认构造的模块容器(如 <code>Linear()</code>)调用底层模块的默认构造函数(<code>LinearImpl()</code>)。如果底层模块没有默认构造函数，则编译错误。要构造空的容器，可以传递 <code>nullptr</code> 至容器的构造函数。</p>
<p>实际上，这意味着可以像之前演示那样使用模块，在初始化列表里注册和构造模块：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;</span><br><span class="line">    Net(<span class="keyword">int64_t</span> N, <span class="keyword">int64_t</span> M) </span><br><span class="line">        : linear(register_module(<span class="string">"linear"</span>, torch::nn::Linear(N, M))) &#123;&#125;</span><br><span class="line">    torch::nn::Linear linear;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>或者可以先构造一个空指针容器，之后在构造函数里分配它：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Net</span> :</span> torch::nn::Module &#123;</span><br><span class="line">    Net(<span class="keyword">int64_t</span> N, <span class="keyword">int64_t</span> M) &#123;</span><br><span class="line">        linear = register_module(<span class="string">"linear"</span>, torch::nn::Linear(N, M));</span><br><span class="line">    &#125;</span><br><span class="line">    torch::nn::Linear linear&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>C++ 前端最优地支持由模块容器提供的所有权模型。这种机制唯一的缺点就是在模块声明下多一行模板引用。也就是说，最简单的模型仍然是在 C++ 模块介绍中展示的值语义模型。对于简单模型，可以使用它。但由于技术原因，并不是总是支持它。例如，序列化 API(<code>torch::save</code> 和 <code>torch::load</code>)仅支持模块容器(或者<code>shared_ptr</code>)。因此，模块容器 API 是 C++ 前端定义模块的推荐方式，接下来都将用这种 API。</p>
<h2><span id="defining-the-dcgan-modules">Defining the DCGAN Modules</span></h2><p>现在有了必要的背景和介绍来定义要解决的机器学习问题所需的模块。回顾一下：任务是生成 MNIST 数据集的数字。想要使用生成对抗网络(GAN)来完成任务。特别地，将使用第一个也是最简单的一个 DCGAN 结构，但足以完成任务。</p>
<h3><span id="what-was-a-gan">What was a GAN</span></h3><p>GAN 由两个不同神经网络模型组成：生成器和鉴别器。生成器接收来自噪声分布的样本，它的目的是将每个噪声样本转换为类似于目标分布的图像，这儿是 MNIST 数据集。鉴别器接收 MNIST 的真实图像，或者生成器产生的虚假图像。它被要求判断图像的多真(接近1)或者多假(接近0)的可能性。由鉴别器产生的关于生成器产生的图片有多真实的反馈用来训练生成器。鉴别器的辨识度的反馈用来优化鉴别器。理论上，生成器和鉴别器间微妙的平衡使它们同步提升，使得生成器产生与目标分布无法区分的图像，从而欺骗鉴别器都真实和虚假的图像均生成0.5的可能性。这里的最终结果是接收一张噪声图像，生成真实的数字的图像。</p>
<h3><span id="the-generator-module">The Generator Module</span></h3><p>定义生成器模型，其由一系列的转置的2维卷积，批处理规范化和 ReLU 激活单元组成。与 Python 一样，PyTorch 提供两种 API 定义模型：一个函数式 API，输入是传递连续的函数；另一个是面向对象的 API，构建一个包含整个模型的 <code>Sequential</code> 模块作为子模块。首先使用 <code>Sequential</code> 构建生成器：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> torch;</span><br><span class="line"></span><br><span class="line">nn::<span class="function">Sequential <span class="title">generator</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 1</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(kNoiseSize, <span class="number">256</span>, <span class="number">4</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::BatchNorm(<span class="number">256</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::relu),</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 2</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">256</span>, <span class="number">128</span>, <span class="number">3</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::BatchNorm(<span class="number">128</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::relu),</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 3</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">128</span>, <span class="number">64</span>, <span class="number">4</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::BatchNorm(<span class="number">64</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::relu),</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 4</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">64</span>, <span class="number">1</span>, <span class="number">4</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::<span class="built_in">tanh</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>选择特定的模块，如 <code>nn::Conv2d</code> 和 <code>nn::BatchNorm</code>，遵循之前概述的结构。常量 <code>kNoiseSize</code> 决定输入噪声向量的大小，并被设为 <code>100</code>。注意这儿使用 <code>torch::nn::Functional</code> 模块作为激活函数，将 <code>torch::relu</code> 传递给它作为内部层，<code>torch::tanh</code> 作为最后的激活。</p>
<p><strong>注意：</strong></p>
<p>在 Python 前端中每个激活函数都有相应的模块，如 <code>torch.nn.ReLU</code> 或者 <code>torch.nn.Tanh</code>。在 C++ 中，仅提供 <code>Functional</code> 模块，可以传递任意将在 <code>Functional</code>的 <code>forward()</code> 方法内被调用的 C++ 函数。</p>
<p>对于第二种方法，在自定义的模块 <code>forward()</code> 方法内的显示地在两个模块间传递输入(以函数的方式)：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">GANGeneratorImpl</span> :</span> nn::Module &#123;</span><br><span class="line">	</span><br><span class="line">	GANGeneratorImpl() :</span><br><span class="line">		conv1(nn::Conv2dOptions(kNoiseSize, <span class="number">512</span>, <span class="number">4</span>)</span><br><span class="line">			.with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span><br><span class="line">		batch_norm1(<span class="number">512</span>),</span><br><span class="line">		conv2(nn::Conv2dOptions(<span class="number">512</span>, <span class="number">256</span>, <span class="number">4</span>)</span><br><span class="line">			.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span><br><span class="line">		batch_norm2(<span class="number">256</span>),</span><br><span class="line">		conv3(nn::Conv2dOptions(<span class="number">256</span>, <span class="number">128</span>, <span class="number">4</span>)</span><br><span class="line">			.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span><br><span class="line">		batch_norm3(<span class="number">128</span>),</span><br><span class="line">		conv4(nn::Conv2dOptions(<span class="number">128</span>, <span class="number">64</span>, <span class="number">4</span>)</span><br><span class="line">			.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)),</span><br><span class="line">		batch_norm4(<span class="number">64</span>),</span><br><span class="line">		conv5(nn::Conv2dOptions(<span class="number">64</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">			.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>).transposed(<span class="literal">true</span>)) </span><br><span class="line">	&#123;&#125;</span><br><span class="line"></span><br><span class="line">	torch::<span class="function">Tensor <span class="title">forward</span><span class="params">(torch::Tensor x)</span> </span>&#123;</span><br><span class="line">		x = torch::relu(batch_norm1(conv1(x)));</span><br><span class="line">		x = torch::relu(batch_norm2(conv2(x)));</span><br><span class="line">		x = torch::relu(batch_norm3(conv3(x)));</span><br><span class="line">		x = torch::relu(batch_norm4(conv4(x)));</span><br><span class="line">		x = torch::<span class="built_in">tanh</span>(conv5(x));</span><br><span class="line">		<span class="keyword">return</span> x;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	nn::Conv2d conv1, conv2, conv3, conv4, conv5;</span><br><span class="line">	nn::BatchNorm batch_norm1, batch_norm2, batch_norm3, batch_norm4;</span><br><span class="line">&#125;;</span><br><span class="line">TORCH_MODULE(GANGenerator);</span><br><span class="line"></span><br><span class="line">GANGenerator generator;</span><br></pre></td></tr></table></figure>
<p>无论使用哪种方法，都可以调用 <code>Generator</code> 的 <code>forward()</code> 来将噪声样本映射至图像。</p>
<p><strong>注意：</strong><br>简单说明一下在 C++ 前端中内置模块如 <code>Conv2d</code> 等要传递的选项：每个模块都有一些选项，如 <code>BatchNorm</code> 的特征数量。如果需要配置某些选项，直接传递给模块的构造函数即可，如 <code>BatchNorm(128)</code> 或者 <code>Dropout(0.5)</code> 或者 <code>Conv2d(8, 4, 2)</code>。也可以修改其他带有默认值的选项，例如<code>Conv2d</code> 的 <code>with_bias</code>，需要构造并传递选项。C++ 前端中的每个模块都有一个相关的选项结构体，被称为 <code>ModuleOptions</code>，其中 <code>Module</code> 是模块的名称，比如 <code>Linear</code> 的 <code>LinearOptions</code>。</p>
<h3><span id="the-discriminator-module">The Discriminator Module</span></h3><p>鉴别器也是一个卷积，批处理规范化和激活的序列。但是，现在的卷积是常规的而不是转置的，并且使用 $\alpha = 0.2$的 leaky ReLU 代替普通的 ReLU。同时，最终的激活函数为 Sigmoid，它将值压缩至[0, 1]。然后这些被压缩的值作为鉴别器认为图像真实的可能性：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">nn::<span class="function">Sequential <span class="title">discriminator</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 1</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">1</span>, <span class="number">64</span>, <span class="number">4</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::leaky_relu, <span class="number">0.2</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 2</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">64</span>, <span class="number">128</span>, <span class="number">4</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::BatchNorm(<span class="number">128</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::leaky_relu, <span class="number">0.2</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 3</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">128</span>, <span class="number">256</span>, <span class="number">4</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">2</span>).padding(<span class="number">1</span>).with_bias(<span class="literal">false</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::BatchNorm(<span class="number">256</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::leaky_relu, <span class="number">0.2</span>),</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment">// Layer 4</span></span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Conv2d(nn::Conv2dOptions(<span class="number">256</span>, <span class="number">1</span>, <span class="number">3</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		.stride(<span class="number">1</span>).padding(<span class="number">0</span>).with_bias(<span class="literal">false</span>)),</span></span></span><br><span class="line"><span class="function"><span class="params">	nn::Functional(torch::sigmoid)</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong></p>
<p>当传递至 <code>Functional</code> 的函数接收的参数多于一个张量时，将这些参数传给 <code>Functional</code> 的构造函数，它会将这些参数传给这些函数。对于上面的 leaky ReLU，这意味着调用的是 <code>torch::leaky_relu(tensor, 0.2)</code>。</p>
<h1><span id="loading-data">Loading Data</span></h1><p>已经定义了生成器和鉴别器模型，需要些训练这些模型的数据。C++ 前端和 Python 前端一样，有强大的并行数据加载器。该数据加载器能够从数据集中读取批量数据，并提供许多配置开关。</p>
<p><strong>注意：</strong><br>Python 的数据加载器使用多进程，而 C++ 的数据加载器是真多线程，而不用开启任何新进程。</p>
<p>数据加载器是 C++ 前端的 <code>data</code> API 的一部分，包含在 <code>torch::data</code> 命名空间内。这个 API 由几个不同组件组成：</p>
<ul>
<li>数据加载器类</li>
<li>一个定义数据集的 API</li>
<li>一个定义数据变换的 API，可用于数据集</li>
<li>一个定义采样器的 API，生成用于索引数据集的索引</li>
<li>一个现有数据集，变换，采样器的库</li>
</ul>
<p>接着实例化一个 <code>torch::data::datasets:::MNIST</code>，并应用两个变换：第一，标准化图像，因此它们的值范围在[-1,1] (原范围为[0,1])。第二，使用 <code>Stack</code> 排序，接收批量的张量，并将它们沿着第一个维度堆叠为一个张量。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> dataset = torch::data::datasets::MNIST(<span class="string">"./mnist"</span>)</span><br><span class="line">	.<span class="built_in">map</span>(torch::data::transforms::Normalize&lt;&gt;(<span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">	.<span class="built_in">map</span>(torch::data::transforms::Stack&lt;&gt;());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这句必须先于 data_loader，不然报异常 "未加载 ucrtbase.pdb"</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int64_t</span> batches_per_epoch = <span class="built_in">std</span>::<span class="built_in">ceil</span>(</span><br><span class="line">    dataset.size().value() / <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(kBatchSize));</span><br></pre></td></tr></table></figure>
<p>注意 MNIST 数据集应该位于执行训练二进制文件的同级目录下的 <code>./mnist</code> 目录，否则会报异常 “未加载 kernelbase.pdb”。接着创建一个数据加载器，并传入该数据集。要创建新的数据加载器，使用 <code>torch::data::make_data_loader</code>，返回一个正确类型的 <code>std::unique_ptr</code>(取决于数据集的类型，采样器的类型和其他的实现细节)：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> data_loader = torch::data::make_data_loader(<span class="built_in">std</span>::move(dataset));</span><br></pre></td></tr></table></figure>
<p>数据加载器由许多选项，可在 <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/data/dataloader_options.h" target="_blank" rel="noopener">github</a> 上查看全部定义。例如，要加速数据加载，可以增加线程的数量。默认值是0，这意味着使用主线程。如果将 <code>workers</code> 设为 <code>2</code>，则生成两个线程来同时加载数据。同时应该将批大小由默认值<code>1</code>增加为其他更合理的值，如 <code>64</code> (<code>kBatchSize</code> 的值)。因此创建一个 <code>DataLoaderOptions</code> 对象，并设置适当的属性：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> data_loader = torch::data::make_data_loader(</span><br><span class="line">	<span class="built_in">std</span>::move(dataset),</span><br><span class="line">	torch::data::DataLoaderOptions().batch_size(kBatchSize).workers(<span class="number">2</span>));</span><br></pre></td></tr></table></figure>
<p>现在编写一个循环加载批量数据，打印至控制台：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (torch::data::Example&lt;&gt; &amp;batch : *data_loader) &#123;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Batch size: "</span> &lt;&lt; batch.data.size(<span class="number">0</span>) &lt;&lt; <span class="string">" | Labels: "</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int64_t</span> i = <span class="number">0</span>; i &lt; batch.data.size(<span class="number">0</span>); ++i) &#123;</span><br><span class="line">		<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; batch.target[i].item&lt;<span class="keyword">int64_t</span>&gt;() &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个示例的数据加载器返回的类型是 <code>torch::data::Example</code>。该类型是一个简单的结构体，有一个 <code>data</code> 字段指向数据，一个 <code>target</code> 字段指向标签。因为之前应用了 <code>Stack</code> 排序规则，数据加载器返回的仅是一个这样的样例。如果没应用排序规则，则数据加载器将生成 <code>std::vector&lt;torch::data::Example&lt;&gt;&gt;</code>，一个元素对应批处理的一个样例。</p>
<h1><span id="writing-the-training-loop">Writing the Training Loop</span></h1><p>下面完成示例的算法部分，并实现生成器和鉴别器直接的微妙。首先，创建两个优化器，一模型一个。优化器用 <a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="noopener">Adam</a> 算法来实现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch::optim::<span class="function">Adam <span class="title">generator_optimizer</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">	generator-&gt;parameters(), torch::optim::AdamOptions(<span class="number">2e-4</span>).beta1(<span class="number">0.5</span>))</span></span>;</span><br><span class="line">torch::optim::<span class="function">Adam <span class="title">discriminator_optimizer</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">	discriminator-&gt;parameters(), torch::optim::AdamOptions(<span class="number">5e-4</span>).beta1(<span class="number">0.5</span>))</span></span>;</span><br></pre></td></tr></table></figure>
<p>接下来更新训练循环，添加一个外部循环来每轮遍历完数据加载器，然后编写 GAN 训练代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int64_t</span> epoch = <span class="number">1</span>; epoch &lt;= kNumberOfEpochs; ++epoch) &#123;</span><br><span class="line">	<span class="keyword">int64_t</span> batch_index = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (torch::data::Example&lt;&gt; &amp;batch : *data_loader) &#123;</span><br><span class="line">		<span class="comment">// 用真实数据训练鉴别器</span></span><br><span class="line">		discriminator-&gt;zero_grad();</span><br><span class="line">		torch::Tensor real_images = batch.data;</span><br><span class="line">		torch::Tensor real_labels = torch::empty(batch.data.size(<span class="number">0</span>)).uniform_(<span class="number">0.8</span>, <span class="number">1.0</span>);</span><br><span class="line">		torch::Tensor real_output = discriminator-&gt;forward(real_images);</span><br><span class="line">		torch::Tensor d_loss_real = torch::binary_cross_entropy(real_output, real_labels);</span><br><span class="line">		d_loss_real.backward();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 用虚假数据训练鉴别器</span></span><br><span class="line">		torch::Tensor noise = torch::randn(&#123; batch.data.size(<span class="number">0</span>), kNoiseSize, <span class="number">1</span>, <span class="number">1</span> &#125;);</span><br><span class="line">		torch::Tensor fake_images = generator-&gt;forward(noise);</span><br><span class="line">		torch::Tensor fake_labels = torch::zeros(batch.data.size(<span class="number">0</span>));</span><br><span class="line">		torch::Tensor fake_output = discriminator-&gt;forward(fake_images.detach());</span><br><span class="line">		torch::Tensor d_loss_fake = torch::binary_cross_entropy(fake_output, fake_labels);</span><br><span class="line">		d_loss_fake.backward();</span><br><span class="line"></span><br><span class="line">		torch::Tensor d_loss = d_loss_real + d_loss_fake;</span><br><span class="line">		discriminator_optimizer.step();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 训练生成器</span></span><br><span class="line">		generator-&gt;zero_grad();</span><br><span class="line">		fake_labels.fill_(<span class="number">1</span>);</span><br><span class="line">		fake_output = discriminator-&gt;forward(fake_images);</span><br><span class="line">		torch::Tensor g_loss = torch::binary_cross_entropy(fake_output, fake_labels);</span><br><span class="line">		g_loss.backward();</span><br><span class="line">		generator_optimizer.step();</span><br><span class="line"></span><br><span class="line">		<span class="built_in">std</span>::<span class="built_in">printf</span>(<span class="string">"\r[%2ld/%2ld][%3ld/%3ld] D_loss: %.4f | G_loss: %.4f"</span>,</span><br><span class="line">			epoch, kNumberOfEpochs, ++batch_index, batches_per_epoch,</span><br><span class="line">			d_loss.item&lt;<span class="keyword">float</span>&gt;(), g_loss.item&lt;<span class="keyword">float</span>&gt;());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码中，先在真实图像上评估鉴别器，应该有一个较高的可能性。因此，使用 <code>torch::empty(batch.data.size(0)).uniform_(0.8, 1.0)</code> 作为目标可能性。为了使得鉴别器的训练更加健壮，使用均匀分布在[0.8, 1.0]的随机值而不是全1.0，这个技巧叫做标签平滑。</p>
<p>在评估鉴别器前，先清空它的参数的梯度。计算损失之后，调用 <code>d_loss.backward()</code> 在网络中进行反向传播来计算新的梯度。在虚假图像上重复该步骤。不使用数据集里的图像，而是喂给生成器一批随机的噪声，让它生成虚假的图像。然后把这些图像传给鉴别器。这次，鉴别器应该生成较低的可能性，理想情况下全是0。计算完鉴别器在一批真和假图像上的损失后，向前推进鉴别器的优化器，以更新鉴别器的参数。</p>
<p>要训练生成器，同样首先清空它的梯度，然后在虚假图像上重新评估鉴别器。但是，这次鉴别器应该输出非常接近于1的可能性，这表示生成器能够生成欺骗鉴别器认为是真实的(来自数据集的)。因此，将 <code>fake_labels</code> 张量全部填1。最后推进生成器的优化器以更新生成器的参数。</p>
<p>现在应该已经准备好在 CPU 上训练模型了。没有任何代码来捕获状态或者样本的输出，但稍后将添加这些。现在先观察模型正在做什么—稍后将在生成的图像上验证这是否有意义。</p>
<h1><span id="moving-to-the-gpu">Moving to the GPU</span></h1><p>虽然目前脚本能在 CPU 上运行，但卷据网络在 GPU 上更快。把训练移至 GPU 上，需要做两件事情：传递 GPU 设备至已分配的张量，并通过C++ 前端中的张量和模块的 <code>to()</code> 方法显示地复制张量到 GPU 上。实现这两这的最简单的方法是在训练脚本顶部创建一个 <code>torch::Device</code> 实例，然后该实例传递给创建张量的函数，如 <code>torch::zeros</code> 和<code>to()</code> 方法：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// torch::Device device(torch::kCPU); // 定义设备为 CPU</span></span><br><span class="line">torch::<span class="function">Device <span class="title">device</span><span class="params">(torch::kCUDA)</span></span>;</span><br><span class="line">torch::Tensor fake_labels = torch::zeros(batch.data.size(<span class="number">0</span>), device); </span><br><span class="line">torch::Tensor real_images = batch.data.to(device);</span><br><span class="line"></span><br><span class="line">generator-&gt;to(device);</span><br><span class="line">discriminator-&gt;to(device);</span><br></pre></td></tr></table></figure>
<p>如果想指定设备索引，它将作为 <code>Device</code> 的构造函数的第二个参数被传入。如果想张量存储在不同设备上，可以分别传递设备(如一个在CUDA 0，另一个在 CUDA 1)。可以动态配置设备，确保脚本更兼容：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch::Device device = torch::kCPU;</span><br><span class="line"><span class="keyword">if</span> (torch::cuda::is_available()) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"CUDA is available! Training on GPU."</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    device = torch::kCUDA;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch::<span class="function">Device <span class="title">device</span><span class="params">(torch::cuda::is_available() ? torch::kCUDA : torch::kCPU)</span></span>;</span><br></pre></td></tr></table></figure>
<h1><span id="checkpointing-and-recovering-the-training-state">Checkpointing and Recovering the Training State</span></h1><p>最后一点加强的是确保训练脚本定期保存模型的参数状态，优化器的状态和一些生成的图像样例。如果训练过程中计算机崩溃，前两个状态将能够恢复训练。对于长时间的训练，这是绝对必要的。幸运地，C++ 前端提供一个 API 来序列化和反序列化模型和优化器的状态，以及单独的张量。</p>
<p>核心 API 是 <code>torch::save(thing, filename)</code> 和 <code>torch::load(thing, filename)</code>，<code>thing</code> 可以是 <code>torch::nn::Module</code> 的子类或者优化器实例，如训练脚本使用的 <code>Adam</code> 对象。现在来更新训练循环，设置检查点在一段时间间隔保存模型和优化器的状态：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (batch_index % kCheckpointEvery == <span class="number">0</span>) &#123;</span><br><span class="line">    torch::save(generator, <span class="string">"generator-checkpoint.pt"</span>);</span><br><span class="line">    torch::save(generator_optimizer, <span class="string">"generator-optimizer-checkpoint.pt"</span>);</span><br><span class="line">    torch::save(discriminator, <span class="string">"discriminator-checkpoint.pt"</span>);</span><br><span class="line">    torch::save(discriminator_optimizer, <span class="string">"discriminator-optimizer-checkpoint.pt"</span>);</span><br><span class="line">    torch::Tensor samples = generator-&gt;forward(torch::randn(&#123; <span class="number">9</span>, kNoiseSize, <span class="number">1</span>, <span class="number">1</span> &#125;, device));</span><br><span class="line">    torch::save((samples + <span class="number">1.0</span>) / <span class="number">2.0</span>, torch::str(<span class="string">"dcgan-sample-"</span>, checkpoint_counter, <span class="string">".pt"</span>));</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"\n-&gt; checkpoint "</span> &lt;&lt; ++checkpoint_counter &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>kCheckpointEvery</code> 是一个整数值，如设为100则表示每100批次检查一次，而 <code>checkpoint_counter</code> 是计数器，每次检查时加1。要恢复训练状态，在创建模型和优化器之后，训练之前添加如下代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (kRestoreFromCheckpoint) &#123;</span><br><span class="line">    torch::load(generator, <span class="string">"generator-checkpoint.pt"</span>);</span><br><span class="line">    torch::load(generator_optimizer, <span class="string">"generator-optimizer-checkpoint.pt"</span>);</span><br><span class="line">    torch::load(discriminator, <span class="string">"discriminator-checkpoint.pt"</span>);</span><br><span class="line">    torch::load(</span><br><span class="line">        discriminator_optimizer, <span class="string">"discriminator-optimizer-checkpoint.pt"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1><span id="inspecting-generated-images">Inspecting Generated Images</span></h1><p>训练脚本已经完成，已经准备好训练 GAN，不管是在 CPU 或者 GPU 上。要查看训练程序的中间输出，添加代码来定期地保存样例至 <code>&quot;dcgan-sample-xxx.pt&quot;</code> 文件，可以编写一个 Python 脚本来加载张量和用 matplotlib 显示它们：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"-i"</span>, <span class="string">"--sample-file"</span>, required=<span class="keyword">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-o"</span>, <span class="string">"--out-file"</span>, default=<span class="string">"out.png"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-d"</span>, <span class="string">"--dimension"</span>, type=int, default=<span class="number">3</span>)</span><br><span class="line">options = parser.parse_args()</span><br><span class="line"></span><br><span class="line">module = torch.jit.load(options.sample_file)</span><br><span class="line">images = list(module.parameters())[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(options.dimension * options.dimension):</span><br><span class="line">    image = images[index].detach().cpu().reshape(<span class="number">28</span>, <span class="number">28</span>).mul(<span class="number">255</span>).to(torch.uint8)</span><br><span class="line">    array = image.numpy()</span><br><span class="line">    axis = plt.subplot(options.dimension, options.dimension, <span class="number">1</span> + index)</span><br><span class="line">    plt.imshow(array, cmap=<span class="string">'gray'</span>)</span><br><span class="line">    axis.get_xaxis().set_visible(<span class="keyword">False</span>)</span><br><span class="line">    axis.get_yaxis().set_visible(<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">plt.savefig(options.out_file)</span><br><span class="line">print(<span class="string">"Saved "</span>, options.out_file)</span><br></pre></td></tr></table></figure>
<p>下面训练模型30轮：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Linux</span><br><span class="line">make &amp;&amp; ./dcgan</span><br><span class="line"># Windows 直接通过vs编译后运行</span><br><span class="line">./dcgan.exe</span><br></pre></td></tr></table></figure>
<p>训练完后显示生成的示例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python display.py -i dcgan-sample-100.pt</span><br><span class="line"><span class="meta">#</span> output: Save out.png</span><br></pre></td></tr></table></figure>
<h1><span id="conclusion">Conclusion</span></h1><p>本章介绍了 PyTorch 的 C++ 前端，PyTorch 有非常广泛的 API，因此，还有很多概念没有介绍到。可以在遇到问题时查询 <a href="https://pytorch.org/cppdocs/" target="_blank" rel="noopener">PyTorch C++ 文档</a>，尤其是<a href="https://pytorch.org/cppdocs/api/library_root.html" target="_blank" rel="noopener">库 API 文档</a>。同时，PyTorch C++ 前端会尽可能遵循 Python 前端的设计和语法。</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ML/" rel="tag"><i class="fa fa-tag"></i> ML</a>
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/PyTorch/" rel="tag"><i class="fa fa-tag"></i> PyTorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/06/14-在C-中加载PyTorch模型-Loading-a-PyTorch-Model-in-C/" rel="next" title="14.在C++中加载PyTorch模型 (Loading a PyTorch Model in C++)">
                <i class="fa fa-chevron-left"></i> 14.在C++中加载PyTorch模型 (Loading a PyTorch Model in C++)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/08/16-PyTorch-C-API/" rel="prev" title="16.PyTorch C++ API">
                16.PyTorch C++ API <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">QWERDF007</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">21</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">10</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/QWERDF007" title="GitHub &rarr; https://github.com/QWERDF007" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">Using the PyTorch C++ Frontend</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">Writing a Basic Application</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.1.</span> <span class="nav-text">Windows</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.2.</span> <span class="nav-text">Linux</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">Defining the Neural Network Models</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">4.1.</span> <span class="nav-text">Module API Basics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.1.1.</span> <span class="nav-text">Defining a Module and Registering Parmmeters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.1.2.</span> <span class="nav-text">Registering Submodules and Traversing the Module Hierarchy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.1.3.</span> <span class="nav-text">Running the Network in Forward Mode</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.1.4.</span> <span class="nav-text">Module Ownership</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">4.2.</span> <span class="nav-text">Defining the DCGAN Modules</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.2.1.</span> <span class="nav-text">What was a GAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.2.2.</span> <span class="nav-text">The Generator Module</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.2.3.</span> <span class="nav-text">The Discriminator Module</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">Loading Data</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">Writing the Training Loop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">Moving to the GPU</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">Checkpointing and Recovering the Training State</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">9.</span> <span class="nav-text">Inspecting Generated Images</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">10.</span> <span class="nav-text">Conclusion</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">QWERDF007</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v6.7.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.7.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.7.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  



  











  





  

  
  <script>
    
    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(counter.time + 1);
            })
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1}))
                .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function () {
                  console.log('Failed to create');
                });
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "Krm9HI5SLyUYN5cnLvBfPp6C-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "Krm9HI5SLyUYN5cnLvBfPp6C-gzGzoHsz",
                'X-LC-Key': "787aFD6m4QVDw9BhnJTF05E0",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });
  </script>



  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>